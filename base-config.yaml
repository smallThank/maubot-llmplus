allowed_users: []

use_platform: local_ai

name: "ollama"

reply_in_thread: true

enable_multi_user: true

system_prompt: ""

platforms:
  local_ai:
    type: ollama
    url: http://192.168.32.162:11434
    api_key:
    model: llama3.2
    max_words: 1000
    max_context_messages: 20
  openai:
    url:
    api_key:
    model:
    max_tokens:
    max_words:
    temperature:
  anthropic:
    url:
    api_key:
    max_tokens:
    model:
    max_words:

additional_prompt:
  - role: user
    content: xxx
  - role: system
    content: xxx