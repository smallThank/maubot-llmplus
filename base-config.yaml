# allow users
allowed_users: []

# current use platform
use_platform: local_ai

# bot name
name: "ai bot"

reply_in_thread: true

enable_multi_user: true

# system prompt
system_prompt: "response in chinese"

# platform config
platforms:
  local_ai:
    type: ollama
    url: http://192.168.32.162:11434
    api_key:
    model: llama3.2
    temperature: 1
    max_tokens: 2000
    max_words: 1000
    max_context_messages: 20
  openai:
    url: https://api.openai.com
    api_key:
    model: gpt-4o-mini
    max_tokens: 2000
    max_words: 1000
    max_context_messages: 20
    temperature: 1
  anthropic:
    url: https://api.anthropic.com
    api_key:
    model: claude-3-5-sonnet-20240620
    max_words: 1000
    max_tokens: 2000
    max_context_messages: 20
  xai:
    url: curl https://api.x.ai
    api_key:
    model: grok-beta
    temperature: 1

# additional prompt
additional_prompt:
  - role: user
    content: "What model is currently in use?"
  - role: system
    content: "you can response text contain user name"